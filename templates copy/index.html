<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Echo Cancellation</title>
    <style>
        canvas {
            border: 1px solid #000;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <h1>WebRTC Echo Cancellation</h1>
    <input type="file" id="audioFileInput" accept="audio/*">
    <button id="playButton">Play Audio File</button>
    <div>
        <h3>Microphone Input</h3>
        <canvas id="micCanvas" width="800" height="200"></canvas>
    </div>
    <div>
        <h3>After Echo Cancellation</h3>
        <canvas id="processedCanvas" width="800" height="200"></canvas>
    </div>

    <script>
        let audioContext;
        let stream;
        let processedStream;
        let micSource;
        let processedSource;
        let analyserMic;
        let analyserProcessed;
        let audioElement;

        const audioFileInput = document.getElementById('audioFileInput');
        const playButton = document.getElementById('playButton');
        const micCanvas = document.getElementById('micCanvas');
        const processedCanvas = document.getElementById('processedCanvas');
        const micCtx = micCanvas.getContext('2d');
        const processedCtx = processedCanvas.getContext('2d');

        playButton.addEventListener('click', playAudioFile);

        // Start audio processing immediately
        window.addEventListener('load', startAudioProcessing);

        async function startAudioProcessing() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();

                // Set up microphone input without echo cancellation
                stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: false } });
                micSource = audioContext.createMediaStreamSource(stream);

                // Set up processed stream with echo cancellation
                const constraints = {
                    echoCancellation: true,
                    noiseSuppression: false,
                    autoGainControl: false
                };
                processedStream = await navigator.mediaDevices.getUserMedia({ audio: constraints });
                processedSource = audioContext.createMediaStreamSource(processedStream);

                // Set up analyzers
                analyserMic = audioContext.createAnalyser();
                analyserProcessed = audioContext.createAnalyser();
                analyserMic.fftSize = 2048;
                analyserProcessed.fftSize = 2048;

                micSource.connect(analyserMic);
                processedSource.connect(analyserProcessed);

                // Start updating waveforms
                updateWaveforms();
            } catch (error) {
                console.error('Error starting audio processing:', error);
            }
        }

        async function playAudioFile() {
            if (audioFileInput.files.length > 0) {
                const file = audioFileInput.files[0];
                const arrayBuffer = await file.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                if (audioElement) {
                    audioElement.stop();
                }
                
                audioElement = audioContext.createBufferSource();
                audioElement.buffer = audioBuffer;
                audioElement.connect(audioContext.destination);
                audioElement.start();
            } else {
                alert('Please select an audio file first.');
            }
        }

        function updateWaveforms() {
            const micData = new Uint8Array(analyserMic.frequencyBinCount);
            const processedData = new Uint8Array(analyserProcessed.frequencyBinCount);
            
            analyserMic.getByteTimeDomainData(micData);
            analyserProcessed.getByteTimeDomainData(processedData);

            drawWaveform(micCtx, micData);
            drawWaveform(processedCtx, processedData);

            requestAnimationFrame(updateWaveforms);
        }

        function drawWaveform(ctx, data) {
            ctx.fillStyle = 'rgb(200, 200, 200)';
            ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height);

            ctx.lineWidth = 2;
            ctx.strokeStyle = 'rgb(0, 0, 0)';

            ctx.beginPath();

            const sliceWidth = ctx.canvas.width * 1.0 / data.length;
            let x = 0;

            for (let i = 0; i < data.length; i++) {
                const v = data[i] / 128.0;
                const y = v * ctx.canvas.height / 2;

                if (i === 0) {
                    ctx.moveTo(x, y);
                } else {
                    ctx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            ctx.lineTo(ctx.canvas.width, ctx.canvas.height / 2);
            ctx.stroke();
        }
    </script>
</body>
</html>
