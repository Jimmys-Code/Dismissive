<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Echo Cancellation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #e0e0e0;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #121212;
        }
        h1, h3 {
            color: #ff9800;
        }
        button {
            background-color: #ff9800;
            color: #121212;
            border: none;
            padding: 10px 15px;
            margin: 5px;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s, transform 0.1s;
            font-weight: bold;
        }
        button:hover {
            background-color: #ffa726;
            transform: translateY(-2px);
        }
        button:disabled {
            background-color: #616161;
            color: #9e9e9e;
            cursor: not-allowed;
            transform: none;
        }
        input[type="file"] {
            margin-bottom: 10px;
            color: #ff9800;
        }
        .volume-control {
            margin: 15px 0;
        }
        input[type="range"] {
            -webkit-appearance: none;
            width: 200px;
            height: 8px;
            background: #424242;
            outline: none;
            border-radius: 4px;
            margin-right: 10px;
        }
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            background: #ff9800;
            cursor: pointer;
            border-radius: 50%;
        }
        input[type="range"]::-moz-range-thumb {
            width: 20px;
            height: 20px;
            background: #ff9800;
            cursor: pointer;
            border-radius: 50%;
        }
        canvas {
            border: 1px solid #ff9800;
            margin: 10px 0;
            box-shadow: 0 0 10px rgba(255, 152, 0, 0.3);
            border-radius: 5px;
        }
        .waveform-container {
            background-color: #1e1e1e;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
            box-shadow: 0 0 10px rgba(255, 152, 0, 0.1);
        }
    </style>
</head>
<body>
    <h1>WebRTC Echo Cancellation</h1>
    
    <div>
        <input type="file" id="audioFileInput" accept="audio/*">
        <button id="playButton">Play Local Audio File</button>
        <button id="playServerButton">Play Server Audio File</button>
        <button id="startRecordingButton">Start Recording</button>
        <button id="stopRecordingButton" disabled>Stop Recording</button>
    </div>
    
    <div class="volume-control">
        <label for="inputVolumeControl">Input Volume:</label>
        <input type="range" id="inputVolumeControl" min="0" max="1" step="0.1" value="1">
        <span id="inputVolumeValue">1.0</span>
    </div>
    
    <div class="volume-control">
        <label for="outputVolumeControl">Output Volume:</label>
        <input type="range" id="outputVolumeControl" min="0" max="2" step="0.1" value="1">
        <span id="outputVolumeValue">1.0</span>
    </div>
    
    <div class="waveform-container">
        <h3>Server Input</h3>
        <canvas id="micCanvas" width="760" height="200"></canvas>
    </div>
    
    <div class="waveform-container">
        <h3>After Echo Cancellation</h3>
        <canvas id="processedCanvas" width="760" height="200"></canvas>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <script>
        let audioContext;
        let serverAudioBuffer;
        let processedStream;
        let serverSource;
        let processedSource;
        let analyserServer;
        let analyserProcessed;
        let audioElement;
        let mediaRecorder;
        let recordedChunks = [];
        let inputGainNode;
        let outputGainNode;

        const audioFileInput = document.getElementById('audioFileInput');
        const playButton = document.getElementById('playButton');
        const playServerButton = document.getElementById('playServerButton');
        const startRecordingButton = document.getElementById('startRecordingButton');
        const stopRecordingButton = document.getElementById('stopRecordingButton');
        const micCanvas = document.getElementById('micCanvas');
        const processedCanvas = document.getElementById('processedCanvas');
        const micCtx = micCanvas.getContext('2d');
        const processedCtx = processedCanvas.getContext('2d');
        const inputVolumeControl = document.getElementById('inputVolumeControl');
        const inputVolumeValue = document.getElementById('inputVolumeValue');
        const outputVolumeControl = document.getElementById('outputVolumeControl');
        const outputVolumeValue = document.getElementById('outputVolumeValue');

        playButton.addEventListener('click', playLocalAudioFile);
        playServerButton.addEventListener('click', requestServerAudioFile);
        startRecordingButton.addEventListener('click', startRecording);
        stopRecordingButton.addEventListener('click', stopRecording);
        inputVolumeControl.addEventListener('input', updateInputVolume);
        outputVolumeControl.addEventListener('input', updateOutputVolume);

        // Start audio processing immediately
        window.addEventListener('load', startAudioProcessing);

        const socket = io();

        socket.on('audio_data', function(data) {
            if (serverAudioBuffer) {
                serverAudioBuffer.copyToChannel(new Float32Array(data.data), 0);
            }
        });

        socket.on('audio_file_data', function(data) {
            playServerAudioFile(data.data);
        });

        async function startAudioProcessing() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();

                // Set up server audio input
                serverAudioBuffer = audioContext.createBuffer(1, 1024, 44100);
                serverSource = audioContext.createBufferSource();
                serverSource.buffer = serverAudioBuffer;
                serverSource.loop = true;
                serverSource.start();

                // Set up processed stream with echo cancellation
                const constraints = {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: false
                };
                processedStream = await navigator.mediaDevices.getUserMedia({ audio: constraints });
                processedSource = audioContext.createMediaStreamSource(processedStream);

                // Create and connect input gain node
                inputGainNode = audioContext.createGain();
                inputGainNode.gain.value = 1.0;
                processedSource.connect(inputGainNode);

                // Create and connect output gain node
                outputGainNode = audioContext.createGain();
                outputGainNode.gain.value = 1.0;

                // Set up analyzers
                analyserServer = audioContext.createAnalyser();
                analyserProcessed = audioContext.createAnalyser();
                analyserServer.fftSize = 2048;
                analyserProcessed.fftSize = 2048;

                serverSource.connect(analyserServer);
                inputGainNode.connect(outputGainNode);
                outputGainNode.connect(analyserProcessed);

                // Start updating waveforms
                updateWaveforms();
            } catch (error) {
                console.error('Error starting audio processing:', error);
            }
        }

        function updateInputVolume() {
            const volume = parseFloat(inputVolumeControl.value);
            inputGainNode.gain.setValueAtTime(volume, audioContext.currentTime);
            inputVolumeValue.textContent = volume.toFixed(1);
        }

        function updateOutputVolume() {
            const volume = parseFloat(outputVolumeControl.value);
            outputGainNode.gain.setValueAtTime(volume, audioContext.currentTime);
            outputVolumeValue.textContent = volume.toFixed(1);
        }

        async function playLocalAudioFile() {
            if (audioFileInput.files.length > 0) {
                const file = audioFileInput.files[0];
                const arrayBuffer = await file.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                if (audioElement) {
                    audioElement.stop();
                }
                
                audioElement = audioContext.createBufferSource();
                audioElement.buffer = audioBuffer;
                audioElement.connect(audioContext.destination);
                audioElement.start();
            } else {
                alert('Please select an audio file first.');
            }
        }

        function requestServerAudioFile() {
            socket.emit('request_audio_file');
        }

        async function playServerAudioFile(base64Data) {
            const binaryString = atob(base64Data);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);

            if (audioElement) {
                audioElement.stop();
            }

            audioElement = audioContext.createBufferSource();
            audioElement.buffer = audioBuffer;
            audioElement.connect(audioContext.destination);
            audioElement.start();
        }

        function updateWaveforms() {
            const serverData = new Uint8Array(analyserServer.frequencyBinCount);
            const processedData = new Uint8Array(analyserProcessed.frequencyBinCount);
            
            analyserServer.getByteTimeDomainData(serverData);
            analyserProcessed.getByteTimeDomainData(processedData);

            drawWaveform(micCtx, serverData);
            drawWaveform(processedCtx, processedData);

            requestAnimationFrame(updateWaveforms);
        }

        function drawWaveform(ctx, data) {
            ctx.fillStyle = '#1e1e1e';
            ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height);

            ctx.lineWidth = 2;
            ctx.strokeStyle = '#ff9800';

            ctx.beginPath();

            const sliceWidth = ctx.canvas.width * 1.0 / data.length;
            let x = 0;

            for (let i = 0; i < data.length; i++) {
                const v = data[i] / 128.0;
                const y = v * ctx.canvas.height / 2;

                if (i === 0) {
                    ctx.moveTo(x, y);
                } else {
                    ctx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            ctx.lineTo(ctx.canvas.width, ctx.canvas.height / 2);
            ctx.stroke();

            // Add a glow effect
            ctx.shadowBlur = 10;
            ctx.shadowColor = '#ff9800';
            ctx.stroke();
            ctx.shadowBlur = 0;
        }

        function startRecording() {
            recordedChunks = [];
            const dest = audioContext.createMediaStreamDestination();
            outputGainNode.connect(dest);

            mediaRecorder = new MediaRecorder(dest.stream);
            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) {
                    recordedChunks.push(e.data);
                }
            };
            mediaRecorder.start();

            startRecordingButton.disabled = true;
            stopRecordingButton.disabled = false;
        }

        function stopRecording() {
            mediaRecorder.stop();
            startRecordingButton.disabled = false;
            stopRecordingButton.disabled = true;

            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'audio/wav' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                document.body.appendChild(a);
                a.style = 'display: none';
                a.href = url;
                a.download = 'echo_cancelled_audio.wav';
                a.click();
                window.URL.revokeObjectURL(url);
            };
        }
    </script>
</body>
</html>
